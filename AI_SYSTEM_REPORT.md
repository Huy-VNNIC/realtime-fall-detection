# ü§ñ AI System Report - Fall Detection

## üìä T√¨nh tr·∫°ng hi·ªán t·∫°i

### ‚úÖ ƒê√£ ho·∫°t ƒë·ªông (OpenCV-based)
1. **Background Subtraction** - Ph√°t hi·ªán chuy·ªÉn ƒë·ªông (MOG2)
2. **Contour Analysis** - Ph√¢n t√≠ch h√¨nh d·∫°ng v·∫≠t th·ªÉ
3. **Kalman Filter Tracking** - Theo d√µi nhi·ªÅu ng∆∞·ªùi
4. **State Machine** - Qu·∫£n l√Ω tr·∫°ng th√°i (STANDING ‚Üí FALLING ‚Üí FALLEN ‚Üí ALARM)
5. **Risk Scoring** - T√≠nh ƒëi·ªÉm nguy c∆° 0-100

### ‚ö†Ô∏è Ch∆∞a ho·∫°t ƒë·ªông (ML-based)
1. **ML Classifier** - Ch∆∞a c√≥ model ƒë∆∞·ª£c train
   - File c·∫ßn: `ai/models/fall_classifier.pkl`
   - Status: Missing
   - Impact: H·ªá th·ªëng d√πng rule-based, nhi·ªÅu false alarm

---

## üß† AI System Architecture

### 1. Feature Extraction (39 features)

#### A. Geometric Features (Instant)
```python
1. aspect_ratio          # width/height (>1.5 = lying)
2. angle                 # rotation (90¬∞ = horizontal)
3. centroid_x, centroid_y # v·ªã tr√≠ tr·ªçng t√¢m
4. bbox_height, bbox_width # k√≠ch th∆∞·ªõc
5. bbox_area            # di·ªán t√≠ch
6. extent               # m·ª©c ƒë·ªô ƒë·∫ßy bbox
7. solidity             # ƒë·ªô ƒë·∫∑c
```

#### B. Motion Features (Temporal)
```python
8-12.  velocity_x, velocity_y, velocity_magnitude
13-17. velocity statistics (mean, std, min, max, range)
18-22. aspect_ratio statistics (trend over 30 frames)
23-27. centroid_y statistics (downward movement)
28-32. bbox_height statistics (height decrease)
33-35. peak_velocity_y (sudden drop)
36-39. current_state (last frame features)
```

### 2. ML Classifier Pipeline

```
Raw Frame ‚Üí Feature Extraction ‚Üí 39D Vector ‚Üí ML Model ‚Üí Prediction
                                                           ‚Üì
                                            {class: 'fall'/'not_fall',
                                             proba: 0.0-1.0,
                                             confidence: 0.0-1.0}
```

**Supported Models:**
- Random Forest (default, best for this problem)
- SVM (Support Vector Machine)
- Logistic Regression
- XGBoost (c·∫ßn c√†i th√™m)
- Neural Network (c·∫ßn c√†i th√™m)

### 3. Training Data Collection

**Current system:**
```bash
# Thu th·∫≠p data ng√£ (60 gi√¢y)
cd data
python collector.py --mode fall --duration 60

# Thu th·∫≠p data kh√¥ng ng√£ (60 gi√¢y)
python collector.py --mode not_fall --duration 60

# Training
python train.py
```

**Data format:**
- CSV files v·ªõi 39 features + 1 label
- Saved in `data/datasets/`
- Auto-split: 80% train, 20% test

---

## üéØ Ch·ª©c nƒÉng AI s·∫Ω mang l·∫°i

### 1. Gi·∫£m False Alarm (Quan tr·ªçng nh·∫•t!)
**V·∫•n ƒë·ªÅ hi·ªán t·∫°i:**
- OpenCV detect m·ªçi chuy·ªÉn ƒë·ªông nhanh ‚Üí ALARM
- Ng∆∞·ªùi ng·ªìi, c√∫i xu·ªëng ‚Üí False alarm
- V·∫≠t r∆°i, b√≥ng ƒë·ªï ‚Üí False alarm

**V·ªõi AI:**
- H·ªçc pattern th·∫≠t c·ªßa ng√£ (t·ª´ data)
- Ph√¢n bi·ªát ng√£ th·∫≠t vs ng√£ gi·∫£
- Confidence score: ch·ªâ alarm khi > 70%

### 2. Adaptive Learning
- Model h·ªçc t·ª´ m√¥i tr∆∞·ªùng th·ª±c t·∫ø
- T·ª± ƒë·ªông c·∫£i thi·ªán qua th·ªùi gian
- Custom cho t·ª´ng kh√¥ng gian (ph√≤ng b·ªánh vi·ªán, nh√† ri√™ng, v.v.)

### 3. Multi-stage Detection
```
Stage 1: OpenCV (Fast)  ‚Üí Candidate detection
Stage 2: ML (Accurate)  ‚Üí False alarm filter  
Stage 3: Deep Learning  ‚Üí Context understanding (future)
```

### 4. Context Awareness
- H·ªçc th√≥i quen c·ªßa ng∆∞·ªùi d√πng
- Detect abnormal behavior
- Time-of-day sensitivity

---

## üöÄ K·∫ø ho·∫°ch ph√°t tri·ªÉn AI

### Phase 1: Basic ML (Hi·ªán t·∫°i)
‚úÖ Feature extraction (39 features)
‚úÖ Random Forest classifier
‚úÖ Training pipeline
‚ö†Ô∏è C·∫ßn: Collect data & train

### Phase 2: Advanced ML (Tu·∫ßn n√†y)
- [ ] XGBoost integration (better accuracy)
- [ ] Ensemble methods (voting classifier)
- [ ] Online learning (continuous improvement)
- [ ] Auto-retraining based on user feedback

### Phase 3: Deep Learning (Th√°ng sau)
- [ ] CNN for pose estimation (MediaPipe/OpenPose)
- [ ] LSTM for temporal modeling
- [ ] Attention mechanism
- [ ] Transfer learning from pre-trained models

### Phase 4: Production AI (2-3 th√°ng)
- [ ] Edge AI optimization (TensorRT/ONNX)
- [ ] Federated learning (privacy-preserving)
- [ ] Explainable AI (why alarm triggered)
- [ ] A/B testing framework

---

## üìà Performance Metrics (Target)

### OpenCV Only (Current)
- Accuracy: ~70%
- False Positive Rate: ~30% (cao!)
- Latency: 10ms/frame
- CPU Usage: 15%

### With ML (After training)
- Accuracy: ~85-90% 
- False Positive Rate: <10%
- Latency: 15ms/frame
- CPU Usage: 20%

### With Deep Learning (Future)
- Accuracy: >95%
- False Positive Rate: <5%
- Latency: 30ms/frame
- CPU/GPU Usage: 40%

---

## üîß H∆∞·ªõng d·∫´n Train AI Model

### Quick Start (5 ph√∫t)

```bash
# B∆∞·ªõc 1: Collect data ng√£
cd data
python collector.py --mode fall --duration 60
# ‚Üí Th·ª±c hi·ªán: ng√£ xu·ªëng, n·∫±m tr√™n s√†n, rolling, v.v.

# B∆∞·ªõc 2: Collect data kh√¥ng ng√£
python collector.py --mode not_fall --duration 120
# ‚Üí Th·ª±c hi·ªán: ƒëi l·∫°i, ng·ªìi, ƒë·ª©ng, c√∫i xu·ªëng nh·∫∑t ƒë·ªì, v.v.

# B∆∞·ªõc 3: Train model
python train.py --model random_forest
# ‚Üí Output: ../ai/models/fall_classifier.pkl

# B∆∞·ªõc 4: Enable AI
cd ..
# Edit config.yaml: ml_classifier.enabled = true

# B∆∞·ªõc 5: Run with AI
python main.py
```

### Advanced Training

```bash
# Train v·ªõi nhi·ªÅu models
python train.py --model all  # Test t·∫•t c·∫£ models

# Cross-validation
python train.py --cv 5

# Grid search hyperparameters
python train.py --optimize

# Export metrics
python train.py --export-metrics results.json
```

---

## üí° AI Best Practices

### 1. Data Collection Tips
- **Balance classes**: 50% fall, 50% not_fall
- **Diverse scenarios**: nhi·ªÅu ki·ªÉu ng√£, nhi·ªÅu ng∆∞·ªùi
- **Edge cases**: ng·ªìi xu·ªëng nhanh, nh·∫£y m√∫a, yoga
- **Lighting conditions**: s√°ng/t·ªëi/backlight
- **Min data**: 500 samples m·ªói class

### 2. Feature Engineering
- Current: 39 handcrafted features
- Future: Auto feature learning (CNN)
- Add context: time, location, user profile

### 3. Model Selection
- **Random Forest**: Best for small data (<10k samples)
- **XGBoost**: Best for medium data (10k-100k)
- **Deep Learning**: Best for large data (>100k)

### 4. Deployment
- Model versioning (MLflow)
- A/B testing (Champion vs Challenger)
- Monitoring drift (data/concept)
- Rollback mechanism

---

## üéì Technical Deep Dive

### Why ML > Rule-based?

**Rule-based (Current without ML):**
```python
if aspect_ratio > 1.5 and velocity_y > threshold:
    return "FALL"  # ‚ùå Too simple!
```
- Fixed thresholds ‚Üí kh√¥ng adapt
- Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c edge cases
- Nhi·ªÅu false positives

**ML-based:**
```python
# Model learns complex decision boundary
prediction = model.predict(features)  # ‚úÖ Smart!
```
- Learn t·ª´ data th·ª±c t·∫ø
- Handle non-linear patterns
- Confidence scores

### Feature Importance (Example)

Sau khi train, model s·∫Ω cho bi·∫øt feature n√†o quan tr·ªçng:

```
1. aspect_ratio_trend       (0.25) - Quan tr·ªçng nh·∫•t!
2. centroid_y_speed        (0.18)
3. height_change_ratio     (0.15)
4. velocity_magnitude_max  (0.12)
5. angle_mean              (0.10)
...
```

‚Üí Gi√∫p optimize detection logic

---

## üîÆ Future AI Roadmap

### Short-term (1-2 th√°ng)
1. **Pose Estimation**: Detect body keypoints (MediaPipe)
2. **Anomaly Detection**: Unsupervised learning
3. **Multi-modal**: Camera + Wearable sensors

### Mid-term (3-6 th√°ng)
1. **Video Understanding**: 3D CNN / Transformers
2. **Activity Recognition**: T·ªïng h·ª£p c√°c ho·∫°t ƒë·ªông
3. **Predictive Analytics**: D·ª± ƒëo√°n nguy c∆°

### Long-term (6-12 th√°ng)
1. **Edge AI**: Deploy on Raspberry Pi / Jetson Nano
2. **Federated Learning**: Multi-site training
3. **Explainable AI**: Visual explanations
4. **Multimodal Fusion**: Camera + Audio + Radar

---

## üìö References & Resources

### Papers
- "Deep Learning for Fall Detection" (IEEE)
- "Human Activity Recognition using CNNs" 
- "Temporal Convolutional Networks for Action Recognition"

### Tools
- MediaPipe (Google): Pose estimation
- OpenPose (CMU): Body keypoints
- TensorRT (NVIDIA): GPU acceleration
- MLflow: Model management

### Datasets
- UR Fall Detection Dataset
- Le2i Fall Detection Dataset  
- Multi-camera Fall Dataset

---

## üéØ Action Items

### Ngay l·∫≠p t·ª©c
- [ ] Collect training data (2 gi·ªù)
- [ ] Train first model (5 ph√∫t)
- [ ] Test & validate (30 ph√∫t)
- [ ] Fine-tune thresholds (1 gi·ªù)

### Tu·∫ßn n√†y
- [ ] Implement XGBoost
- [ ] Add online learning
- [ ] Create dashboard for metrics
- [ ] User feedback system

### Th√°ng n√†y
- [ ] Integrate pose estimation
- [ ] Deep learning prototype
- [ ] Edge deployment test
- [ ] Performance optimization

---

**Status**: üü° AI Infrastructure ready, needs training data
**Next Step**: Run data collection script
**ETA to full AI**: 2-3 hours of data collection + training
